{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "from torch.nn import BCELoss\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import binary_cross_entropy\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vnetpyt import vnet as Vnet\n",
    "\n",
    "from mod3DUnet import Modified3DUNet as UNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 16 04:02:38 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 410.104      Driver Version: 410.104      CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-DGXS...  On   | 00000000:0E:00.0 Off |                    0 |\r\n",
      "| N/A   36C    P0    49W / 300W |   4571MiB / 32478MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0816 04:02:39.916503 140345729128256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/niftynet/__init__.py:36: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0816 04:02:39.987415 140345729128256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/niftynet/utilities/util_import.py:28: The name tf.logging.fatal is deprecated. Please use tf.compat.v1.logging.fatal instead.\n",
      "\n",
      "E0816 04:02:39.989434 140345729128256 util_import.py:36] CRITICAL - Optional Python module cv2 not found, please install cv2 and retry if the application fails.\n",
      "E0816 04:02:39.990676 140345729128256 util_import.py:36] CRITICAL - Optional Python module skimage.io not found, please install skimage.io and retry if the application fails.\n",
      "W0816 04:02:40.059309 140345729128256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/niftynet/io/misc_io.py:645: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0816 04:02:40.060607 140345729128256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/niftynet/io/misc_io.py:759: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W0816 04:02:40.061618 140345729128256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/niftynet/io/misc_io.py:759: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mWARNING:niftynet:\u001b[0m From /usr/local/lib/python3.6/dist-packages/niftynet/engine/application_variables.py:20: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 04:02:40.756999 140345729128256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/niftynet/engine/application_variables.py:20: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mWARNING:niftynet:\u001b[0m From /usr/local/lib/python3.6/dist-packages/niftynet/engine/application_variables.py:21: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 04:02:40.758990 140345729128256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/niftynet/engine/application_variables.py:21: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mWARNING:niftynet:\u001b[0m From /usr/local/lib/python3.6/dist-packages/niftynet/engine/application_variables.py:22: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 04:02:40.760592 140345729128256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/niftynet/engine/application_variables.py:22: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from niftynet.engine.sampler_grid_v2 import GridSampler\n",
    "from niftynet.engine.sampler_uniform_v2 import UniformSampler\n",
    "from niftynet.engine.signal import TRAIN, VALID, INFER\n",
    "from niftynet.engine.windows_aggregator_grid import GridSamplesAggregator\n",
    "from niftynet.engine.windows_aggregator_base import ImageWindowsAggregator\n",
    "from niftynet.engine.sampler_balanced_v2 import BalancedSampler\n",
    "from niftynet.evaluation.pairwise_measures import PairwiseMeasures\n",
    "from niftynet.io.image_reader import ImageReader\n",
    "from niftynet.io.image_sets_partitioner import ImageSetsPartitioner\n",
    "from niftynet.layer.mean_variance_normalisation import MeanVarNormalisationLayer\n",
    "from niftynet.layer.pad import PadLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetNiftySampler(Dataset):\n",
    "    \"\"\"\n",
    "    A simple adapter\n",
    "    converting NiftyNet sampler's output into PyTorch Dataset properties\n",
    "    \"\"\"\n",
    "    def __init__(self, sampler):\n",
    "        super(DatasetNiftySampler, self).__init__()\n",
    "        self.sampler = sampler\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.sampler(idx=index)\n",
    "\n",
    "        # Transpose to PyTorch format\n",
    "        image = np.transpose(data['image'], (0, 5, 1, 2, 3, 4))\n",
    "        label = np.transpose(data['label'], (0, 5, 1, 2, 3, 4))\n",
    "\n",
    "        image = torch.from_numpy(image).float()\n",
    "        label = torch.from_numpy(label).float()\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sampler.reader.output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftDiceLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SoftDiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, label):\n",
    "        probs = output.view(-1)\n",
    "        mask = label.view(-1)\n",
    "        smooth = 1\n",
    "        intersection = torch.sum(probs * mask)\n",
    "        den1 = torch.sum(probs)\n",
    "        den2 = torch.sum(mask)\n",
    "        soft_dice = (2 * intersection + smooth) / (den1 + den2 + smooth)\n",
    "        return -soft_dice\n",
    "\n",
    "\n",
    "def dice(input, target):\n",
    "    epsilon = 1e-8\n",
    "    iflat = input.view(-1)\n",
    "    tflat = target.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    return 2 * intersection / (iflat.sum() + tflat.sum() + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tversky(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(tversky,self).__init__()\n",
    "        \n",
    "    def forward(self,output,label):\n",
    "        alpha = 0.1\n",
    "        beta  = 0.9\n",
    "\n",
    "        one = torch.ones_like(label)\n",
    "        p0 = output      # proba that voxels are class i\n",
    "        p1 = one-output # proba that voxels are not class i\n",
    "        g0 = label\n",
    "        g1 = one-label\n",
    "\n",
    "        num = torch.sum(p0*g0, (0,1,2,3))\n",
    "        den = num + alpha*torch.sum(p0*g1,(0,1,2,3)) + beta*torch.sum(p1*g0,(0,1,2,3))\n",
    "\n",
    "        T = torch.sum(num/den) # when summing over classes, T has dynamic range [0 Ncl]\n",
    "\n",
    "        Ncl = torch.reshape(label, (-1,)).to(dtype = torch.float32)\n",
    "        #Ncl = K.cast(K.shape(y_true)[-1], 'float32')\n",
    "        return Ncl-T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_per_channel_dice(input, target, epsilon=1e-5, ignore_index=None, weight=None):\n",
    "    # assumes that input is a normalized probability\n",
    "\n",
    "    # input and target shapes must match\n",
    "    assert input.size() == target.size(), \"'input' and 'target' must have the same shape\"\n",
    "\n",
    "    # mask ignore_index if present\n",
    "    if ignore_index is not None:\n",
    "        mask = target.clone().ne_(ignore_index)\n",
    "        mask.requires_grad = False\n",
    "\n",
    "        input = input * mask\n",
    "        target = target * mask\n",
    "\n",
    "    input = flatten(input)\n",
    "    target = flatten(target)\n",
    "\n",
    "    target = target.float()\n",
    "    # Compute per channel Dice Coefficient\n",
    "    intersect = (input * target).sum(-1)\n",
    "    if weight is not None:\n",
    "        intersect = weight * intersect\n",
    "\n",
    "    denominator = (input + target).sum(-1)\n",
    "    return 2. * intersect / denominator.clamp(min=epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralizedDiceLoss(nn.Module):\n",
    "    \"\"\"Computes Generalized Dice Loss (GDL) as described in https://arxiv.org/pdf/1707.03237.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epsilon=1e-5, weight=None, ignore_index=None, sigmoid_normalization=True):\n",
    "        super(GeneralizedDiceLoss, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.register_buffer('weight', weight)\n",
    "        self.ignore_index = ignore_index\n",
    "        if sigmoid_normalization:\n",
    "            self.normalization = nn.Sigmoid()\n",
    "        else:\n",
    "            self.normalization = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # get probabilities from logits\n",
    "        input = self.normalization(input)\n",
    "\n",
    "        assert input.size() == target.size(), \"'input' and 'target' must have the same shape\"\n",
    "\n",
    "        # mask ignore_index if present\n",
    "        if self.ignore_index is not None:\n",
    "            mask = target.clone().ne_(self.ignore_index)\n",
    "            mask.requires_grad = False\n",
    "\n",
    "            input = input * mask\n",
    "            target = target * mask\n",
    "\n",
    "        input = torch.flatten(input)\n",
    "        target = torch.flatten(target)\n",
    "\n",
    "        target = target.float()\n",
    "        target_sum = target.sum(-1)\n",
    "        class_weights = torch.autograd.Variable(1. / (target_sum * target_sum).clamp(min=self.epsilon), requires_grad=False)\n",
    "\n",
    "        intersect = (input * target).sum(-1) * class_weights\n",
    "        if self.weight is not None:\n",
    "            weight = torch.autograd.Variable(self.weight, requires_grad=False)\n",
    "            intersect = weight * intersect\n",
    "        intersect = intersect.sum()\n",
    "\n",
    "        denominator = ((input + target).sum(-1) * class_weights).sum()\n",
    "\n",
    "        return 1. - 2. * intersect / denominator.clamp(min=self.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceCoefficient:\n",
    "    \"\"\"Computes Dice Coefficient.\n",
    "    Generalized to multiple channels by computing per-channel Dice Score\n",
    "    (as described in https://arxiv.org/pdf/1707.03237.pdf) and theTn simply taking the average.\n",
    "    Input is expected to be probabilities instead of logits.\n",
    "    This metric is mostly useful when channels contain the same semantic class (e.g. affinities computed with different offsets).\n",
    "    DO NOT USE this metric when training with DiceLoss, otherwise the results will be biased towards the loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epsilon=1e-5, ignore_index=None, **kwargs):\n",
    "        self.epsilon = epsilon\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def __call__(self, input, target):\n",
    "        \"\"\"\n",
    "        :param input: 5D probability maps torch tensor (NxCxDxHxW)\n",
    "        :param target: 4D or 5D ground truth torch tensor. 4D (NxDxHxW) tensor will be expanded to 5D as one-hot\n",
    "        :return: Soft Dice Coefficient averaged over all channels/classes\n",
    "        \"\"\"\n",
    "        # Average across channels in order to get the final score\n",
    "        return torch.mean(compute_per_channel_dice(input, target, epsilon=self.epsilon, ignore_index=self.ignore_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split_file_new = 'fcd_train_val_infer_split.csv'\n",
    "\n",
    "patch_size = (32,32,32)\n",
    "\n",
    "in_channels = 3 #3?\n",
    "\n",
    "n_classes = 1\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "ratios =[0.1,0.1]\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "cp_path = './CP2.pth'\n",
    "\n",
    "image_path = 'Fcd_Data/'\n",
    "\n",
    "label_path = 'Fcd_Data/Labels'\n",
    "\n",
    "pred_path = 'Fcd_Data/pred_brain'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reader(data_param,task_param,image_sets_partitioner, phase):\n",
    "    \n",
    "    if phase == 'training':\n",
    "        image_reader = ImageReader().initialise(\n",
    "            data_param,task_param = grouping_param,file_list=image_sets_partitioner.get_file_list(TRAIN))\n",
    "\n",
    "\n",
    "    elif phase == 'validation':\n",
    "        image_reader = ImageReader().initialise(\n",
    "            data_param,task_param = grouping_param, file_list=image_sets_partitioner.get_file_list(VALID))\n",
    "        #_, image_data, _ = image_reader(idx=0)\n",
    "\n",
    "\n",
    "    elif phase == 'inference':\n",
    "        image_reader = ImageReader().initialise(\n",
    "            data_param,task_param = grouping_param,file_list=image_sets_partitioner.get_file_list(INFER))\n",
    "        #_, image_data, _ = image_reader(idx=0)\n",
    "\n",
    "    else:\n",
    "        raise Exception('Invalid phase choice: {}'.format(\n",
    "            {'phase': ['train', 'validation', 'inference']}))\n",
    "\n",
    "    \n",
    "    mean_variance_norm_layer = MeanVarNormalisationLayer(image_name='image')\n",
    "    pad_layer = PadLayer(image_name=('image', 'label'), border=(8, 8, 8))\n",
    "    image_reader.add_preprocessing_layers([mean_variance_norm_layer])\n",
    "\n",
    "    if phase == 'inference':\n",
    "        image_reader.add_preprocessing_layers([pad_layer])\n",
    "\n",
    "    return image_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sampler(image_reader, patch_size, phase):\n",
    "    if phase in ('training', 'validation'):\n",
    "        sampler = UniformSampler(image_reader,\n",
    "                                 window_sizes=patch_size,\n",
    "                                 windows_per_image=2)\n",
    "    elif phase == 'inference':\n",
    "        sampler = GridSampler(image_reader,\n",
    "                              window_sizes=patch_size,\n",
    "                              window_border=(8, 8, 8),\n",
    "                              batch_size=1)\n",
    "    else:\n",
    "        raise Exception('Invalid phase choice: {}'.format(\n",
    "            {'phase': ['train', 'validation', 'inference']}))\n",
    "\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dsets, model, optimizer,\n",
    "          num_epochs, device, cp_path, batch_size):\n",
    "    since = time.time()\n",
    "\n",
    "    dataloaders = {\n",
    "        x: DataLoader(dsets[x], batch_size=batch_size,\n",
    "                      shuffle=True, num_workers=4)\n",
    "        for x in ['training', 'validation']}\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['training', 'validation']:\n",
    "            if phase == 'training':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "            epoch_samples = 0\n",
    "            \n",
    "            # Iterate over data\n",
    "            for iteration, (inputs, labels) in enumerate(dataloaders[phase], 1):\n",
    "\n",
    "                nbatches, wsize, nchannels, x, y, z, _ = inputs.size()\n",
    "\n",
    "                inputs = inputs.view(nbatches * wsize, nchannels, x, y, z)\n",
    "                labels = labels.view(nbatches * wsize, 1, x, y, z)\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'training'):\n",
    "                    outputs = model(inputs)\n",
    "                    pred = (outputs > 0.5)\n",
    "\n",
    "                    loss = binary_cross_entropy(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'training':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                measures = PairwiseMeasures(\n",
    "                    pred.cpu().numpy(), labels.cpu().numpy())\n",
    "              \n",
    "\n",
    "            epoch_loss = running_loss / epoch_samples\n",
    "\n",
    "            epoch_acc = running_corrects / epoch_samples\n",
    "\n",
    "            print('{} Loss: {:.4f} Dice: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "                \n",
    "\n",
    "            if epoch == 0:\n",
    "                best_loss = epoch_loss\n",
    "                torch.save(model.state_dict(), cp_path.format(epoch + 1))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'validation' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                torch.save(model.state_dict(), cp_path)\n",
    "                print('Checkpoint {} saved!'.format(epoch + 1))\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(sampler, model, device, pred_path, cp_path):\n",
    "    output = GridSamplesAggregator(image_reader=sampler.reader,\n",
    "                                   window_border=(8, 8, 8),\n",
    "                                   output_path=pred_path)\n",
    "    for _ in sampler():  # for each subject\n",
    "\n",
    "        model.load_state_dict(torch.load(cp_path))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        for batch_output in sampler():  # for each sliding window step\n",
    "            window = batch_output['image']\n",
    "            # [...,0,:] eliminates time coordinate from NiftyNet Volume\n",
    "            window = window[..., 0, :]\n",
    "            window = np.transpose(window, (0, 4, 1, 2, 3))\n",
    "            window = torch.Tensor(window).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(window)\n",
    "\n",
    "            outputs = outputs.cpu().numpy()\n",
    "            outputs = np.transpose(outputs, (0, 2, 3, 4, 1))\n",
    "            output.decode_batch({'window_image': outputs.astype(np.float32)},\n",
    "                                batch_output['image_location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]Reading data\n",
      "[INFO] GPU available\n",
      "\u001b[1mWARNING:niftynet:\u001b[0m From /usr/local/lib/python3.6/dist-packages/niftynet/io/image_sets_partitioner.py:269: The name tf.logging.debug is deprecated. Please use tf.compat.v1.logging.debug instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 04:02:40.903449 140345729128256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/niftynet/io/image_sets_partitioner.py:269: The name tf.logging.debug is deprecated. Please use tf.compat.v1.logging.debug instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mWARNING:niftynet:\u001b[0m Loading from existing partitioning file fcd_train_val_infer_split.csv, ignoring partitioning ratios.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 04:02:40.927857 140345729128256 image_sets_partitioner.py:368] Loading from existing partitioning file fcd_train_val_infer_split.csv, ignoring partitioning ratios.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO:niftynet:\u001b[0m \n",
      "\n",
      "Number of subjects 5, input section names: ['subject_id', 'modal', 'interhemi', 'pvms', 'labels']\n",
      "Dataset partitioning:\n",
      "-- training 3 cases (60.00%),\n",
      "-- validation 1 cases (20.00%),\n",
      "-- inference 1 cases (20.00%).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0816 04:02:40.933712 140345729128256 image_sets_partitioner.py:90] \n",
      "\n",
      "Number of subjects 5, input section names: ['subject_id', 'modal', 'interhemi', 'pvms', 'labels']\n",
      "Dataset partitioning:\n",
      "-- training 3 cases (60.00%),\n",
      "-- validation 1 cases (20.00%),\n",
      "-- inference 1 cases (20.00%).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mWARNING:niftynet:\u001b[0m From /usr/local/lib/python3.6/dist-packages/niftynet/layer/base_layer.py:26: The name tf.make_template is deprecated. Please use tf.compat.v1.make_template instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 04:02:40.943020 140345729128256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/niftynet/layer/base_layer.py:26: The name tf.make_template is deprecated. Please use tf.compat.v1.make_template instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO:niftynet:\u001b[0m Image reader: loading 3 subjects from sections ('modal', 'interhemi', 'pvms') as input [image]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0816 04:02:40.995209 140345729128256 image_reader.py:178] Image reader: loading 3 subjects from sections ('modal', 'interhemi', 'pvms') as input [image]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO:niftynet:\u001b[0m Image reader: loading 3 subjects from sections ('labels',) as input [label]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0816 04:02:40.996316 140345729128256 image_reader.py:178] Image reader: loading 3 subjects from sections ('labels',) as input [label]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "reading datasets headers |----------| 0.0% \r",
      "\u001b[1mINFO:niftynet:\u001b[0m Image reader: loading 1 subjects from sections ('modal', 'interhemi', 'pvms') as input [image]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0816 04:02:41.017948 140345729128256 image_reader.py:178] Image reader: loading 1 subjects from sections ('modal', 'interhemi', 'pvms') as input [image]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO:niftynet:\u001b[0m Image reader: loading 1 subjects from sections ('labels',) as input [label]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0816 04:02:41.019029 140345729128256 image_reader.py:178] Image reader: loading 1 subjects from sections ('labels',) as input [label]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "reading datasets headers |----------| 0.0% \r",
      "\u001b[1mINFO:niftynet:\u001b[0m Image reader: loading 1 subjects from sections ('modal', 'interhemi', 'pvms') as input [image]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0816 04:02:41.051955 140345729128256 image_reader.py:178] Image reader: loading 1 subjects from sections ('modal', 'interhemi', 'pvms') as input [image]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO:niftynet:\u001b[0m Image reader: loading 1 subjects from sections ('labels',) as input [label]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0816 04:02:41.053272 140345729128256 image_reader.py:178] Image reader: loading 1 subjects from sections ('labels',) as input [label]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO:niftynet:\u001b[0m initialised uniform sampler {'image': (2, 32, 32, 32, 1, 3), 'image_location': (2, 7), 'label': (2, 32, 32, 32, 1, 1), 'label_location': (2, 7)} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0816 04:02:41.074945 140345729128256 sampler_uniform_v2.py:45] initialised uniform sampler {'image': (2, 32, 32, 32, 1, 3), 'image_location': (2, 7), 'label': (2, 32, 32, 32, 1, 1), 'label_location': (2, 7)} \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO:niftynet:\u001b[0m initialised uniform sampler {'image': (2, 32, 32, 32, 1, 3), 'image_location': (2, 7), 'label': (2, 32, 32, 32, 1, 1), 'label_location': (2, 7)} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0816 04:02:41.093401 140345729128256 sampler_uniform_v2.py:45] initialised uniform sampler {'image': (2, 32, 32, 32, 1, 3), 'image_location': (2, 7), 'label': (2, 32, 32, 32, 1, 1), 'label_location': (2, 7)} \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO:niftynet:\u001b[0m initialised window instance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0816 04:02:41.106134 140345729128256 sampler_grid_v2.py:53] initialised window instance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO:niftynet:\u001b[0m initialised grid sampler {'image': (1, 32, 32, 32, 1, 3), 'image_location': (1, 7), 'label': (1, 32, 32, 32, 1, 1), 'label_location': (1, 7)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0816 04:02:41.107379 140345729128256 sampler_grid_v2.py:54] initialised grid sampler {'image': (1, 32, 32, 32, 1, 3), 'image_location': (1, 7), 'label': (1, 32, 32, 32, 1, 1), 'label_location': (1, 7)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Building model\n",
      "[INFO] Training\n",
      "Epoch 1/50\n",
      "----------\n",
      "training Loss: 0.7476 Dice: 0.0000\n",
      "validation Loss: 0.7502 Dice: 0.0000\n",
      "\n",
      "Epoch 2/50\n",
      "----------\n",
      "training Loss: 0.7398 Dice: 0.0000\n",
      "validation Loss: 0.6777 Dice: 0.0000\n",
      "Checkpoint 2 saved!\n",
      "\n",
      "Epoch 3/50\n",
      "----------\n",
      "training Loss: 0.6643 Dice: 0.0000\n",
      "validation Loss: 0.6364 Dice: 0.0000\n",
      "Checkpoint 3 saved!\n",
      "\n",
      "Epoch 4/50\n",
      "----------\n",
      "training Loss: 0.6156 Dice: 0.0000\n",
      "validation Loss: 0.5868 Dice: 0.0000\n",
      "Checkpoint 4 saved!\n",
      "\n",
      "Epoch 5/50\n",
      "----------\n",
      "training Loss: 0.5613 Dice: 0.0000\n",
      "validation Loss: 0.5422 Dice: 0.0000\n",
      "Checkpoint 5 saved!\n",
      "\n",
      "Epoch 6/50\n",
      "----------\n",
      "training Loss: 0.5147 Dice: 0.0000\n",
      "validation Loss: 0.5042 Dice: 0.0000\n",
      "Checkpoint 6 saved!\n",
      "\n",
      "Epoch 7/50\n",
      "----------\n",
      "training Loss: 0.4795 Dice: 0.0000\n",
      "validation Loss: 0.4701 Dice: 0.0000\n",
      "Checkpoint 7 saved!\n",
      "\n",
      "Epoch 8/50\n",
      "----------\n",
      "training Loss: 0.4370 Dice: 0.0000\n",
      "validation Loss: 0.4382 Dice: 0.0000\n",
      "Checkpoint 8 saved!\n",
      "\n",
      "Epoch 9/50\n",
      "----------\n",
      "training Loss: 0.4064 Dice: 0.0000\n",
      "validation Loss: 0.4105 Dice: 0.0000\n",
      "Checkpoint 9 saved!\n",
      "\n",
      "Epoch 10/50\n",
      "----------\n",
      "training Loss: 0.3851 Dice: 0.0000\n",
      "validation Loss: 0.3858 Dice: 0.0000\n",
      "Checkpoint 10 saved!\n",
      "\n",
      "Epoch 11/50\n",
      "----------\n",
      "training Loss: 0.3552 Dice: 0.0000\n",
      "validation Loss: 0.3645 Dice: 0.0000\n",
      "Checkpoint 11 saved!\n",
      "\n",
      "Epoch 12/50\n",
      "----------\n",
      "training Loss: 0.3355 Dice: 0.0000\n",
      "validation Loss: 0.3442 Dice: 0.0000\n",
      "Checkpoint 12 saved!\n",
      "\n",
      "Epoch 13/50\n",
      "----------\n",
      "training Loss: 0.3208 Dice: 0.0000\n",
      "validation Loss: 0.3263 Dice: 0.0000\n",
      "Checkpoint 13 saved!\n",
      "\n",
      "Epoch 14/50\n",
      "----------\n",
      "training Loss: 0.3019 Dice: 0.0000\n",
      "validation Loss: 0.3097 Dice: 0.0000\n",
      "Checkpoint 14 saved!\n",
      "\n",
      "Epoch 15/50\n",
      "----------\n",
      "training Loss: 0.2811 Dice: 0.0000\n",
      "validation Loss: 0.2947 Dice: 0.0000\n",
      "Checkpoint 15 saved!\n",
      "\n",
      "Epoch 16/50\n",
      "----------\n",
      "training Loss: 0.2662 Dice: 0.0000\n",
      "validation Loss: 0.2807 Dice: 0.0000\n",
      "Checkpoint 16 saved!\n",
      "\n",
      "Epoch 17/50\n",
      "----------\n",
      "training Loss: 0.2576 Dice: 0.0000\n",
      "validation Loss: 0.2679 Dice: 0.0000\n",
      "Checkpoint 17 saved!\n",
      "\n",
      "Epoch 18/50\n",
      "----------\n",
      "training Loss: 0.2454 Dice: 0.0000\n",
      "validation Loss: 0.2563 Dice: 0.0000\n",
      "Checkpoint 18 saved!\n",
      "\n",
      "Epoch 19/50\n",
      "----------\n",
      "training Loss: 0.2314 Dice: 0.0000\n",
      "validation Loss: 0.2459 Dice: 0.0000\n",
      "Checkpoint 19 saved!\n",
      "\n",
      "Epoch 20/50\n",
      "----------\n",
      "training Loss: 0.2225 Dice: 0.0000\n",
      "validation Loss: 0.2360 Dice: 0.0000\n",
      "Checkpoint 20 saved!\n",
      "\n",
      "Epoch 21/50\n",
      "----------\n",
      "training Loss: 0.2097 Dice: 0.0000\n",
      "validation Loss: 0.2266 Dice: 0.0000\n",
      "Checkpoint 21 saved!\n",
      "\n",
      "Epoch 22/50\n",
      "----------\n",
      "training Loss: 0.2115 Dice: 0.0000\n",
      "validation Loss: 0.2178 Dice: 0.0000\n",
      "Checkpoint 22 saved!\n",
      "\n",
      "Epoch 23/50\n",
      "----------\n",
      "training Loss: 0.1935 Dice: 0.0000\n",
      "validation Loss: 0.2093 Dice: 0.0000\n",
      "Checkpoint 23 saved!\n",
      "\n",
      "Epoch 24/50\n",
      "----------\n",
      "training Loss: 0.1905 Dice: 0.0000\n",
      "validation Loss: 0.2017 Dice: 0.0000\n",
      "Checkpoint 24 saved!\n",
      "\n",
      "Epoch 25/50\n",
      "----------\n",
      "training Loss: 0.1878 Dice: 0.0000\n",
      "validation Loss: 0.1953 Dice: 0.0000\n",
      "Checkpoint 25 saved!\n",
      "\n",
      "Epoch 26/50\n",
      "----------\n",
      "training Loss: 0.1736 Dice: 0.0000\n",
      "validation Loss: 0.1888 Dice: 0.0000\n",
      "Checkpoint 26 saved!\n",
      "\n",
      "Epoch 27/50\n",
      "----------\n",
      "training Loss: 0.1723 Dice: 0.0000\n",
      "validation Loss: 0.1830 Dice: 0.0000\n",
      "Checkpoint 27 saved!\n",
      "\n",
      "Epoch 28/50\n",
      "----------\n",
      "training Loss: 0.1596 Dice: 0.0000\n",
      "validation Loss: 0.1760 Dice: 0.0000\n",
      "Checkpoint 28 saved!\n",
      "\n",
      "Epoch 29/50\n",
      "----------\n",
      "training Loss: 0.1595 Dice: 0.0000\n",
      "validation Loss: 0.1700 Dice: 0.0000\n",
      "Checkpoint 29 saved!\n",
      "\n",
      "Epoch 30/50\n",
      "----------\n",
      "training Loss: 0.1495 Dice: 0.0000\n",
      "validation Loss: 0.1646 Dice: 0.0000\n",
      "Checkpoint 30 saved!\n",
      "\n",
      "Epoch 31/50\n",
      "----------\n",
      "training Loss: 0.1433 Dice: 0.0000\n",
      "validation Loss: 0.1594 Dice: 0.0000\n",
      "Checkpoint 31 saved!\n",
      "\n",
      "Epoch 32/50\n",
      "----------\n",
      "training Loss: 0.1385 Dice: 0.0000\n",
      "validation Loss: 0.1544 Dice: 0.0000\n",
      "Checkpoint 32 saved!\n",
      "\n",
      "Epoch 33/50\n",
      "----------\n",
      "training Loss: 0.1334 Dice: 0.0000\n",
      "validation Loss: 0.1498 Dice: 0.0000\n",
      "Checkpoint 33 saved!\n",
      "\n",
      "Epoch 34/50\n",
      "----------\n",
      "training Loss: 0.1311 Dice: 0.0000\n",
      "validation Loss: 0.1453 Dice: 0.0000\n",
      "Checkpoint 34 saved!\n",
      "\n",
      "Epoch 35/50\n",
      "----------\n",
      "training Loss: 0.1278 Dice: 0.0000\n",
      "validation Loss: 0.1411 Dice: 0.0000\n",
      "Checkpoint 35 saved!\n",
      "\n",
      "Epoch 36/50\n",
      "----------\n",
      "training Loss: 0.1226 Dice: 0.0000\n",
      "validation Loss: 0.1371 Dice: 0.0000\n",
      "Checkpoint 36 saved!\n",
      "\n",
      "Epoch 37/50\n",
      "----------\n",
      "training Loss: 0.1201 Dice: 0.0000\n",
      "validation Loss: 0.1335 Dice: 0.0000\n",
      "Checkpoint 37 saved!\n",
      "\n",
      "Epoch 38/50\n",
      "----------\n",
      "training Loss: 0.1132 Dice: 0.0000\n",
      "validation Loss: 0.1299 Dice: 0.0000\n",
      "Checkpoint 38 saved!\n",
      "\n",
      "Epoch 39/50\n",
      "----------\n",
      "training Loss: 0.1101 Dice: 0.0000\n",
      "validation Loss: 0.1265 Dice: 0.0000\n",
      "Checkpoint 39 saved!\n",
      "\n",
      "Epoch 40/50\n",
      "----------\n",
      "training Loss: 0.1097 Dice: 0.0000\n",
      "validation Loss: 0.1232 Dice: 0.0000\n",
      "Checkpoint 40 saved!\n",
      "\n",
      "Epoch 41/50\n",
      "----------\n",
      "training Loss: 0.1067 Dice: 0.0000\n",
      "validation Loss: 0.1201 Dice: 0.0000\n",
      "Checkpoint 41 saved!\n",
      "\n",
      "Epoch 42/50\n",
      "----------\n",
      "training Loss: 0.1037 Dice: 0.0000\n",
      "validation Loss: 0.1172 Dice: 0.0000\n",
      "Checkpoint 42 saved!\n",
      "\n",
      "Epoch 43/50\n",
      "----------\n",
      "training Loss: 0.1010 Dice: 0.0000\n",
      "validation Loss: 0.1143 Dice: 0.0000\n",
      "Checkpoint 43 saved!\n",
      "\n",
      "Epoch 44/50\n",
      "----------\n",
      "training Loss: 0.1016 Dice: 0.0000\n",
      "validation Loss: 0.1113 Dice: 0.0000\n",
      "Checkpoint 44 saved!\n",
      "\n",
      "Epoch 45/50\n",
      "----------\n",
      "training Loss: 0.0988 Dice: 0.0000\n",
      "validation Loss: 0.1088 Dice: 0.0000\n",
      "Checkpoint 45 saved!\n",
      "\n",
      "Epoch 46/50\n",
      "----------\n",
      "training Loss: 0.0918 Dice: 0.0000\n",
      "validation Loss: 0.1062 Dice: 0.0000\n",
      "Checkpoint 46 saved!\n",
      "\n",
      "Epoch 47/50\n",
      "----------\n",
      "training Loss: 0.0938 Dice: 0.0000\n",
      "validation Loss: 0.1037 Dice: 0.0000\n",
      "Checkpoint 47 saved!\n",
      "\n",
      "Epoch 48/50\n",
      "----------\n",
      "training Loss: 0.0890 Dice: 0.0000\n",
      "validation Loss: 0.1014 Dice: 0.0000\n",
      "Checkpoint 48 saved!\n",
      "\n",
      "Epoch 49/50\n",
      "----------\n",
      "training Loss: 0.0897 Dice: 0.0000\n",
      "validation Loss: 0.0992 Dice: 0.0000\n",
      "Checkpoint 49 saved!\n",
      "\n",
      "Epoch 50/50\n",
      "----------\n",
      "training Loss: 0.0875 Dice: 0.0000\n",
      "validation Loss: 0.0971 Dice: 0.0000\n",
      "Checkpoint 50 saved!\n",
      "\n",
      "Training complete in 12m 20s\n",
      "[INFO] Inference\n",
      "\u001b[1mINFO:niftynet:\u001b[0m grid sampling image sizes: {'image': (272, 272, 208, 1, 3), 'label': (272, 272, 208, 1, 1)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0816 04:15:04.958250 140345729128256 sampler_grid_v2.py:77] grid sampling image sizes: {'image': (272, 272, 208, 1, 3), 'label': (272, 272, 208, 1, 1)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO:niftynet:\u001b[0m grid sampling window sizes: {'image': (32, 32, 32, 1, 3), 'label': (32, 32, 32, 1, 1)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0816 04:15:04.959924 140345729128256 sampler_grid_v2.py:79] grid sampling window sizes: {'image': (32, 32, 32, 1, 3), 'label': (32, 32, 32, 1, 1)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO:niftynet:\u001b[0m yielding 3072 locations from image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0816 04:15:04.961242 140345729128256 sampler_grid_v2.py:87] yielding 3072 locations from image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCRITICAL:niftynet:\u001b[0m No feasible samples from \u001b[42m[Layer]\u001b[0m grid_sampler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0816 04:15:04.971232 140345729128256 sampler_grid_v2.py:124] CRITICAL - No feasible samples from \u001b[42m[Layer]\u001b[0m grid_sampler\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'output_dict' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5f1cedf57a4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] Inference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inference'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-edabd5df0fee>\u001b[0m in \u001b[0;36minference\u001b[0;34m(sampler, model, device, pred_path, cp_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for each sliding window step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# [...,0,:] eliminates time coordinate from NiftyNet Volume\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/niftynet/engine/sampler_grid_v2.py\u001b[0m in \u001b[0;36mlayer_op\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m                     \u001b[0moutput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'output_dict' referenced before assignment"
     ]
    }
   ],
   "source": [
    "print(\"[INFO]Reading data\")\n",
    "    # Dictionary with data parameters for NiftyNet Reader\n",
    "if torch.cuda.is_available():\n",
    "    print('[INFO] GPU available')\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "else:\n",
    "    raise Exception(\"[INFO] No GPU found or Wrong gpu id\")\n",
    "\n",
    "    # Dictionary with data parameters for NiftyNet Reader\n",
    "data_param = {\n",
    "        'modal': {'path_to_search': os.path.join(image_path, 'images'), 'filename_contains': 'reg'},\n",
    "        'interhemi': {'path_to_search': os.path.join(image_path, 'Interhemi'), 'filename_contains': 'interasymm'},\n",
    "        'pvms': {'path_to_search': os.path.join(image_path, 'Pvms'), 'filename_contains' : 'pve'},\n",
    "        'labels': {'path_to_search': label_path, 'filename_contains': 'label'}}\n",
    "\n",
    "grouping_param = {'image': ('modal', 'interhemi', 'pvms'), \n",
    "                  'label': ('labels',)}\n",
    "\n",
    "\n",
    "image_sets_partitioner = ImageSetsPartitioner().initialise(\n",
    "        data_param=data_param,\n",
    "        data_split_file=data_split_file_new,\n",
    "        new_partition=False,\n",
    "        ratios = ratios)\n",
    "\n",
    "readers = {x: get_reader(data_param,grouping_param,image_sets_partitioner, x) for x in ['training', 'validation', 'inference']}\n",
    "samplers = {x: get_sampler(readers[x], patch_size, x) for x in ['training', 'validation', 'inference']}\n",
    "\n",
    "    # Training stage only\n",
    "dsets = {x: DatasetNiftySampler(sampler=samplers[x])\n",
    "             for x in ['training', 'validation']}\n",
    "\n",
    "print(\"[INFO] Building model\")\n",
    "model = UNet(in_channels,n_classes)\n",
    "#criterion = binary_cross_entropy(output,labels)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "print(\"[INFO] Training\")\n",
    "train(dsets, model,optimizer,num_epochs, device, cp_path, batch_size)\n",
    "\n",
    "print(\"[INFO] Inference\")\n",
    "inference(samplers['inference'], model, device, pred_path, cp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
